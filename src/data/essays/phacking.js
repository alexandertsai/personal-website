const essay = {
    id: 2,
    title: "Why P-Hacking may not be so bad",
    slug: "p-hacking",
    date: "14 March, 2025",
    preview: "P-hacking, while controversial, may not be causing as much harm as we think",
    content: `

:h3-center: Introduction

P-hacking is defined as the manipulation or cherry-picking of data to turn non-significant results into significant ones. P-hacking is widespread in scientific research (Head et al., 2015). This causes large amounts of false or inaccurate research to be published and may potentially lead to false meta-analyses (Loannidis, 2005; Head et al., 2015). This has disastrous implications in fields such as medical biology or environmental science where accuracy is paramount, and results implicate lives. However, in this essay, I will argue why despite the possibility of p-hacking hindering scientific progress, the effects of such hindrance are contested. Further, due to the mercenary nature of academia, p-hacking is inevitable at times, and may even be beneficial at points, and therefore is acceptable. 

### The Consequences of P-Hacking 

**Hindered Progress and Other Issues** 

Detractors to p-hacking argue that it may lead to many results being false positives (Ioannidis, 2005). Some results, while vowing accuracy, may simply be confirming previously p-hacked results that are subject to prevailing bias. They also argue that p-hacking often results in readers of the papers being unsure if the result was due to the strength of the analytical method, if it was truly a result from the dataset, or if it was simply the product of legitimate decisions by researchers (Anderson, n.d.). If researchers are unable to discern which papers are hacked and which are not, scientific progress may stagnate as the available literature is inaccurate. 

Another worry is that p-hacking may plague the datasets used within meta-analyses (Ioannidis & Pereria, 2011). Meta-analyses are useful tools in providing summaries of currently available literature and often provide a better approximation of the efficacy of a treatment or a solution (Haidich, 2010). As previously stated, inaccurate meta-analyses in medical fields would be catastrophic. 

Other criticisms of p-hacking include how it causes the questioning of the integrity of the sciences and discolors honest academic works. Critics worry less statistically literate public audiences may struggle to recognize certain possible issues within the statistics (Hubbard & Dunbar., 2017) and this could lead to the proliferation of false information derived from heavily p-hacked research. Lastly, it is argued p-hacking misdirects efforts, causing researchers to concentrate on adjusting their p-value rather than their methodology or the hypothesis itself.  

**Debatable Effects** 

While there lies validity in the arguments, the extent to which some of these arguments are impactful is debatable. An eminent study done by Head et al., (2015), which sets out to discourage p-hacking, admits that p-hacking likely does not drastically affect the conclusions from meta-analyses. Further, meta-analyses as a tool itself has issues. A collection of non-significant studies can yield significant results due to various methods in which p-values can be combined, and hence begs the question if p-hacking would affect the result of the meta-analyses in the first place.  

While it remains a possibility that p-hacking could tarnish academia’s reputation, the number of articles that are even read in the first place is questionable (Biswas & Kircherr, 2015). How will a reputation be tarnished if there isn’t one to begin with? Hence, these criticisms should be taken askance. The criticism of inaccurate literature will be addressed further in the paper. 

### Inevitability of the P-Hack 

**Academic Mercenaries** 

The academic realm is not spared from profit maximizing. A disproportionate number of papers with significant results are published in comparison to papers with non-significant ones (Begg & Berlin, 2018; Dwan et al., 2008). This is largely attributed to the monetization schemes behind scientific journals: significant results will attract readers and encourage more to pay or subscribe. This is only exacerbated by the emphasis on a journal’s impact factor (the citation frequency of an average article per annum) — non-significant results are just not cited as often (Fanelli, 2012). For scientists to succeed, publishing a paper before obtaining their PhD is a vital factor (Laurance et al., 2013). It follows that any rational scientist is incentivized to p-hack and churn out papers with significant results simply due to the impact it would have on their future income. 

**Accidental P-hacking** 

There are multitudinous p-hacking strategies (Stefan & Schönbrodt, 2023). Even the most scrupulous researchers would struggle to avoid accidentally utilizing some form of p-hacking. Consider a scientist conducting a study on obesity in teenagers. The scientists diligently accounts for religion, medical history, and personality among other traits. Even so, it is possible that the scientist may have failed to account for social media presence, given they had not even considered it initially. This would then constitute an error of selective reporting of the dependent variable, and they would have accidently “p-hacked”. Evidently, the infinitude of potential variables that could affect the independent variable makes it impossible to never p-hack at all. There will always be some degree of p-hacking present, whether intentional or not. 

**The File Drawer Problem** 

The presence of p-hacking has caused p-hacking critics to call upon The File Drawer Problem (FDP). The FDP is the selective publishing (5%) of studies that show a certain significant result despite most (95%) other studies that were not published indicating otherwise (Rosenthal, 1979). This mostly occurs due to the incentive to p-hack as discussed previously. Repercussions of the FDP are identical to that of p-hacking as previously discussed.  

However, the FDP may not be that significant of an issue. For one, if we were to assume the fields wherein large amounts of studies have already been published and the FDP to be true, unrealistic amounts of studies would have to reside in file drawers to refute the collective results of the already published ones (Rosenthal, 1979). Furthermore, analogous to P-hacking, some extent of the FPD is inevitable due to the impossibility of including every piece of literature in existence when conducting meta-analyses. Lastly, research has pointed to the FDP being overstated and insignificant in affecting meta-analyses (Dalton et al., 2012).  

### Benefits of the P-Hack

**Fischer’s Arbitrary 0.05** 

P-hacking can help important literature get published. The prevalence of the p-value being less than 0.05 in hypothesis testing stemmed from Ronald Fischer’s influential work Statistical Methods For Research Workers (Kennedy-Shaffer, 2019). While it is conveniently approximately equal to a measure of two standard deviations from the mean under a normal distribution, p=0.05 is for the most part, arbitrary (Shaffer., 2019). By imposing such a stringent threshold, research is often polarized into non-significant findings (p>0.05) and significant ones (p<0.05). As mentioned before, significant findings are published, non-significant ones are usually not. This results in the available literature being unrepresentative of the true dataset (Sterling et al., 2012). 

It can then be argued that in the case of a research paper having a p-value slightly above 0.05, or a higher p-value yet a large effect size (the practical significance of the results), p-hacking can aid these papers in being published. Literature that may not initially have p-values of less than 0.05 but is of notable consequence can be made visible and further research can be done in relevant areas. Almost-significant studies that would otherwise be ignored can be analyzed and this may even result in more accurate meta-analyses.  

**Career Advancement** 

To be an academic is a difficult feat. Yet the field of scientific research has risen in importance due to the emergence of global crises such as climate change and food security (The Royal Society, 2010).  A survey done by Nature (2021) reveals industry researchers are typically better paid and more satisfied with their jobs than their academic counterparts. Given the high barriers to entry and the competitiveness of such a pertinent field, p-hacking serves to benefit academics in helping their research be published in prestigious journals and thereafter aiding in career advancement. Without p-hacking, the literature published may fall, which would ultimately impede progression in addressing issues in significant fields. 

**Conclusion** 

This essay demonstrates that despite the existence of potential implications of p-hacking, some of these implications may be overstated, and research points to several of them, such as the FDP and p-hacking in meta-analyses, to be of little consequence vis-à-vis the final conclusions in the research. Due to the often mercenary nature of academia as well as the impossibility of considering every factor, p-hacking is inevitable and may even be beneficial at times. P-hacking aids important literature in overcoming arbitrary p-value thresholds and hence being brought to light. P-hacking is a vital contributor to the survival of the salient field that is scientific research. 

**References** 

Anderson, B. (2017, February 10). P-hacking and the problem of multiple comparisons. Dr Brian Anderson’s Blog. https://info.umkc.edu/drbanderson/p-hacking-and-the-problem-of-multiple-comparisons/  

Andrade C. (2019). The P Value and Statistical Significance: Misunderstandings, Explanations, Challenges, and Alternatives. Indian journal of psychological medicine, 41(3), 210–215. https://doi.org/10.4103/IJPSYM.IJPSYM_193_19 

Berlin JA, Begg CB, Louis TA. An assessment of publication bias using a sample of published clinical trials. J Am Stat Assoc. 1989;84:381–392. 

Biswas, A., & Kirchherr, J. (2015, April 9). Citations are not enough: Academic promotion panels must take into account a scholar’s presence in popular media. LSE Impact Blog. April 15, 2024, https://blogs.lse.ac.uk/impactofsocialsciences/2015/04/09/academic-promotion-scholars-popular-media/  

Corotto, F. S. (2023a). Important things to know about null hypothesis testing. Wise Use of Null Hypothesis Tests, 45–55. https://doi.org/10.1016/b978-0-323-95284-2.00005-7  

Dalton, D. R., Aguinis, H., Dalton, C. M., Bosco, F. A., & Pierce, C. A. (2012). Revisiting the file drawer problem in meta‐analysis: An assessment of published and nonpublished correlation matrices. Personnel Psychology, 65(2), 221–249. https://doi.org/10.1111/j.1744-6570.2012.01243.x  

Dwan, K., Altman, D. G., Arnaiz, J. A., Bloom, J., Chan, A. W., Cronin, E., Decullier, E., Easterbrook, P. J., Von Elm, E., Gamble, C., Ghersi, D., Ioannidis, J. P., Simes, J., & Williamson, P. R. (2008). Systematic review of the empirical evidence of study publication bias and outcome reporting bias. PloS one, 3(8), e3081. https://doi.org/10.1371/journal.pone.0003081 

Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. Scientometrics Scientometrics, 90(3), 891-904. https://doi.org/10.1007/s11192-011-0494-7 

Friese, M., & Frankenbach, J. (2020). P-hacking and publication bias interact to distort meta-analytic effect size estimates. Psychological Methods, 25(4), 456–471. https://doi.org/10.1037/met0000246 

Haidich A. B. (2010). Meta-analysis in medical research. Hippokratia, 14(Suppl 1), 29–37. 

Head, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS biology, 13(3), e1002106. https://doi.org/10.1371/journal.pbio.1002106  

Hubbard, K. E., & Dunbar, S. D. (2017). Perceptions of scientific research literature and strategies for reading papers depend on academic career stage. PloS one, 12(12), e0189753. https://doi.org/10.1371/journal.pone.0189753 

Ioannidis JPA (2005) Why most published research findings are false. PLoS Med 2: e124 

Kennedy-Shaffer L. (2019). Before p < 0.05 to Beyond p < 0.05: Using History to Contextualize p-Values and Significance Testing. The American statistician, 73(Suppl 1), 82–90. https://doi.org/10.1080/00031305.2018.1537891 

Nelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s Renaissance. Annual Review of Psychology, 69(1), 511–534. https://doi.org/10.1146/annurev-psych-122216-011836  

Pereira TV, Ioannidis JPA (2011) Statistically significant meta-analyses of clinical trials have modest credibility and inflated effects. J Clin Epidemiol 64: 1060–1069. 10.1016/j.jclinepi.2010.12.012 

Rosenthal, R. (1979). The file drawer problem and tolerance for null results. Psychological Bulletin, 86(3), 638–641. https://doi.org/10.1037//0033-2909.86.3.638  

Stefan, A. M., & Schönbrodt, F. D. (2023). Big little lies: A compendium and simulation ofp-hacking strategies. Royal Society Open Science, 10(2). https://doi.org/10.1098/rsos.220346  

Sterling, T. D. (1959). Publication decisions and their possible effects on inferences drawn from tests of significance—or vice versa. Journal of the American Statistical Association, 54(285), 30–34. https://doi.org/10.1080/01621459.1959.10501497 

Sterling, T. D., Rosenbaum, W. L., & Weinkam, J. J. (1995). Publication Decisions Revisited: The Effect of the Outcome of Statistical Tests on the Decision to Publish and Vice Versa. The American Statistician, 49(1), 108–112. https://doi.org/10.1080/00031305.1995.10476125 

Sterne, J. A., & Davey Smith, G. (2001). Sifting the evidence-what's wrong with significance tests?. BMJ (Clinical research ed.), 322(7280), 226–231. https://doi.org/10.1136/bmj.322.7280.226 

The scientific century: Securing our future prosperity. (2010). . Royal Society.  

William F. Laurance, D. Carolina Useche, Susan G. Laurance, Corey J. A. Bradshaw, Predicting Publication Success for Biologists, BioScience, Volume 63, Issue 10, October 2013, Pages 817–823, https://doi.org/10.1525/bio.2013.63.10.9  

Woolston, C. (2021). Stagnating salaries present hurdles to career satisfaction. Nature, 599(7885), 519–521. https://doi.org/10.1038/d41586-021-03041-0  
  `
  };
  
  export default essay;